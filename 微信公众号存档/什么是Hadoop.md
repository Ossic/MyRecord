# 什么是Hadoop

>   Apache Hadoop是一款支持数据密集型分布式应用程序并以Apache 2.0许可协议发布的开源软件框架。它支持在商品硬件构建的大型集群上运行的应用程序。
>   Hadoop是根据谷歌公司发表的MapReduce和Google文件系统的论文自行实现而成。
>
>   开发者为Apache软件基金会
>   使用的语言为Java，是跨平台的

再通俗点就是：

Hadoop是一种**分析和处理大数据的软件平台**，是Appach的一个用Java语言所实现的开源软件的加框，在**大量计算机组成的集群**当中实现了对于海量的数据进行的分布式计算。所以说，Hadoop不需要性能强劲的计算机，一般的PC即可，数量当然越多越好

如果专业一点就是：

是专为**离线和大规模数据分析而设计的**，并不适合那种对几个记录随机读写的在线事务处理模式。

**Hadoop = HDFS（文件系统，数据存储技术相关）+ Mapreduce（数据处理）**

Hadoop的数据来源可以是任何形式，在处理半结构化和非结构化数据上与关系型数据库相比有更好的性能，具有更灵活的处理能力，**不管任何数据形式最终会转化为key/value**，key/value是基本数据单元。

用函数式变成Mapreduce代替SQL，SQL是查询语句，而Mapreduce则是使用脚本和代码，而对于适用于关系型数据库，习惯SQL的Hadoop有开源工具hive代替。

Hadoop的另外一个独特之处是：所有的功能都是分布式的，而不是传统数据库的集中式系统。

## 能做什么

hadoop擅长日志分析，facebook就用Hive来进行日志分析，2009年时facebook就有非编程人员的30%的人使用HiveQL进行数据分析

淘宝搜索中的自定义筛选也使用的Hive；利用Pig还可以做高级的数据处理，包括Twitter、LinkedIn上用于发现您可能认识的人，可以实现类似Amazon.com的协同过滤的推荐效果。

淘宝的商品推荐也是！在Yahoo！的40%的Hadoop作业是用pig运行的，包括垃圾邮件的识别和过滤，还有用户特征建模。

分析金融数据来预测未来的走向等

目前使用已经非常广泛了

## Hadoop分布式文件系统（HDFS）

如果提起Hadoop你的大脑一片空白，那么请牢记住这一点：Hadoop有两个主要部分：一个数据处理框架和一个分布式数据存储**文件系统**（HDFS）。

HDFS就像Hadoop系统的篮子，你把数据整整齐齐码放在里面等待数据分析大厨出手变成性感的大餐端到CEO的桌面上。

## 数据处理框架和MapReduce

顾名思义，数据处理框架是处理数据的工具。具体来说Hadoop的数据处理框架是基于Java的系统——MapReduce，你听到MapReduce的次数会比HDFS还要多，这是因为：

1.MapReduce是真正完成数据处理任务的工具

2.MapReduce往往会把它的用户逼疯

有一点容易搞混的是，Hadoop并不是一个真正意义上的数据库：它能存储和抽取数据，但并没有查询语言介入。Hadoop更多是一个数据仓库系统，所以需要MapReduce这样的系统来进行真正的数据处理。

目前有很多工具能够让Hadoop更容易使用，例如Hive，可以将查询语句转换成MapReduce任务。但是MapReduce的复杂性和局限性（单任务批处理）使得Hadoop在更多情况下都被作为数据仓库使用而非数据分析工具。

不过现在来说MapReduce已经比较老旧了，**YARN** 是 Hadoop 下一代资源管理器和应用程序框架，也称为 MapReduce 2.0。MapReduce 作业在 YARN 上运行。

## 一个栗子

我有一个1TP的数据库备份的sql文件.我现在想在不导入到数据库的情况下，通过正则过滤出我想要的内容。如果使用用linux的命令grep或者编程实现的话，小文件还好，如果这种超大文件就显得不太好了

Haddop 就是为了解决这个问题诞生的

Hadoop 要做的事 首先把 1PB的数据文件导入到HDFS中,然后编程人员定义好map和reduce,也就是**把文件的行定义为key,每行的内容定义为value** , 然后进行正则匹配,匹配成功则把结果 通过reduce聚合起来返回.Hadoop 就会把这个程序分布到N 个结点去并行的操作. 那么原本可能需要计算好几天,在有了足够多的结点之后就可以把时间缩小到几小时之内.

这也就是所谓的 大数据 云计算了.如果还是不懂的话再举个简单的例子比如 1亿个 1 相加 得出计算结果, 我们很轻易知道结果是1亿.但是计算机不知道.那么单台计算机处理的方式做一个一亿次的循环每次结果+1那么分布式的处理方式则变成我用1万台计算机,每个计算机只需要计算 1万个 1 相加然后再有一台计算机把1万台计算机得到的结果再相加从而得到最后的结果.

## 最后

关于大数据、云计算，这个话题也不是一两句能说明白的，这里仅仅是说了下最表层的东西，也有很多专业术语，亲身体验一下应该理解的更快